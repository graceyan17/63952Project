{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDPTIAkd3nPod0mIXdQxTa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import json\n","import pandas as pd\n","from tqdm import tqdm\n","import numpy as np"],"metadata":{"id":"R1AtYu8ohc8O","executionInfo":{"status":"ok","timestamp":1764728622159,"user_tz":300,"elapsed":423,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# evaluation functions for recommender PERFORMANCE"],"metadata":{"id":"TRqedWw0h70S","executionInfo":{"status":"ok","timestamp":1764728622165,"user_tz":300,"elapsed":2,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def filter_test_set(test_df, min_user_test_entries):\n","  \"\"\"\n","  filters test set to only include users for whom we have enough data to evaluate them on\n","  \"\"\"\n","  counts = test_df['user_id'].value_counts()\n","  from collections import Counter\n","  counter = Counter(counts)\n","  print(counter)\n","  keep_users = counts[counts >= min_user_test_entries].index\n","  return test_df[test_df['user_id'].isin(keep_users)]"],"metadata":{"id":"IRmfPpkskJlf","executionInfo":{"status":"ok","timestamp":1764728622168,"user_tz":300,"elapsed":1,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def highly_rated_recall_at_k(user_recommendations, train_df, test_df, user_id, k=20):\n","  \"\"\"\n","  user_recommendations: list of book recommendations for the user\n","  train_df: dataset to make recommendations\n","  test_df: validation dataset\n","  user_id: the user's id\n","  k: number of books to recommend\n","\n","  computes recall @ k for highly rated books\n","  \"\"\"\n","  # get set of \"ground truth books\" (books that appear for the user in the test set, which they have rated >= 7)\n","  user_ratings_test = test_df[test_df.user_id == user_id]\n","  if len(user_ratings_test) == 0:\n","    return 0\n","  highly_rated = user_ratings_test[user_ratings_test['rating'] >= 7]\n","  ground_truth = set(highly_rated['join_title'])\n","\n","  num_matches = len([book for book in user_recommendations if book in ground_truth])\n","  user_test_books = len(ground_truth)\n","\n","  return num_matches / user_test_books if user_test_books else 0\n"],"metadata":{"id":"ueT6nAHgh-TW","executionInfo":{"status":"ok","timestamp":1764728622170,"user_tz":300,"elapsed":1,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def recall_at_k(user_recommendations, train_df, test_df, user_id, k=20):\n","  \"\"\"\n","  user_recommendations: list of book recommendations for the user\n","  train_df: dataset to make recommendations\n","  test_df: validation dataset\n","  user_id: the user's id\n","  k: number of books to recommend\n","\n","  computes recall @ k\n","  \"\"\"\n","  # get set of \"ground truth books\" (books that appear for the user in the test set)\n","  user_ratings_test = test_df[test_df.user_id == user_id].copy()\n","  if len(user_ratings_test) == 0:\n","    return 0\n","\n","  ground_truth = set(user_ratings_test['join_title'])\n","\n","  num_matches = len([book for book in user_recommendations if book in ground_truth])\n","  user_test_books = len(ground_truth)\n","\n","  return num_matches / user_test_books if user_test_books else 0"],"metadata":{"id":"N4MVS28-h--C","executionInfo":{"status":"ok","timestamp":1764728622172,"user_tz":300,"elapsed":1,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def precision_at_k(user_recommendations, train_df, test_df, user_id, k=20):\n","  \"\"\"\n","  user_recommendations: list of book recommendations for the user\n","  train_df: dataset to make recommendations\n","  test_df: validation dataset\n","  user_id: the user's id\n","  k: number of books to recommend\n","\n","  computes precision @ k\n","  \"\"\"\n","  # get set of \"ground truth books\" (books that appear for the user in the test set)\n","  user_test = test_df[test_df.user_id == user_id]\n","  if len(user_test) == 0:\n","      return 0\n","  ground_truth = set(user_test['join_title'])\n","\n","  num_matches = len([book for book in user_recommendations if book in ground_truth])\n","\n","  return num_matches / k"],"metadata":{"id":"lH8SafoCiBGv","executionInfo":{"status":"ok","timestamp":1764728622185,"user_tz":300,"elapsed":11,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def highly_rated_precision_at_k(user_recommendations, train_df, test_df, user_id, k=20):\n","  \"\"\"\n","  user_recommendations: list of book recommendations for the user\n","  train_df: dataset to make recommendations\n","  test_df: validation dataset\n","  user_id: the user's id\n","  k: number of books to recommend\n","\n","  computes precision @ k for highly rated books\n","  \"\"\"\n","  # get set of \"ground truth books\" (books that appear for the user in the test set, which they have rated >= 7)\n","  user_test = test_df[test_df.user_id == user_id]\n","  if len(user_test) == 0:\n","      return 0\n","  ground_truth = set(user_test[user_test.rating >= 7]['join_title'])\n","\n","  num_matches = len([book for book in user_recommendations if book in ground_truth])\n","\n","  return num_matches / k"],"metadata":{"id":"4vTvfGUxlOi2","executionInfo":{"status":"ok","timestamp":1764728622188,"user_tz":300,"elapsed":1,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def f1_score(precision, recall):\n","  \"\"\"\n","  computes f1 score from precision and recall\n","  \"\"\"\n","  return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0"],"metadata":{"id":"t8jL8V9jn9g5","executionInfo":{"status":"ok","timestamp":1764728622191,"user_tz":300,"elapsed":1,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def evaluate(recommendations, train_df, test_df, k=20):\n","  \"\"\"\n","  recommendations: a dictionary mapping user_ids (strings) to lists of book recommendations for each user\n","  train_df: dataset to make recommendations\n","  test_df: validation dataset\n","  user_id: the user's id\n","  k: number of books to recommend\n","  \"\"\"\n","  # get data for only evaluation users\n","  valid_user_ids = list(set(train_df.user_id.unique()) & set(test_df.user_id.unique()))\n","\n","  eval_user_ids = [user_id for user_id in test_df.user_id.unique()]\n","\n","  highly_rated_recalls = []\n","  recalls = []\n","  precisions = []\n","  highly_rated_precisions = []\n","  for user_id in tqdm(eval_user_ids):\n","    user_id_str = str(user_id)\n","    user_recommendations = recommendations[user_id_str]\n","    highly_rated_recall = highly_rated_recall_at_k(user_recommendations, train_df, test_df, user_id, k=20)\n","    recall = recall_at_k(user_recommendations, train_df, test_df, user_id, k=20)\n","    precision = precision_at_k(user_recommendations, train_df, test_df, user_id, k=20)\n","    highly_rated_precision = highly_rated_precision_at_k(user_recommendations, train_df, test_df, user_id, k=20)\n","    highly_rated_recalls.append(highly_rated_recall)\n","    recalls.append(recall)\n","    precisions.append(precision)\n","    highly_rated_precisions.append(highly_rated_precision)\n","\n","  f1_scores = [f1_score(p, r) for p, r in zip(precisions, recalls)]\n","  avg_f1_score = np.mean(f1_scores)\n","  highly_rated_f1_scores = [f1_score(p, r) for p, r in zip(highly_rated_precisions, highly_rated_recalls)]\n","  avg_highly_rated_f1_score = np.mean(highly_rated_f1_scores)\n","\n","  avg_highly_rated_recall = np.mean(highly_rated_recalls)\n","  avg_recall = np.mean(recalls)\n","  avg_precision = np.mean(precisions)\n","  avg_highly_rated_precision = np.mean(highly_rated_precisions)\n","\n","  print(f\"\\nAverage recall@k={k}: {avg_recall} for k = {k}\")\n","  print(f\"\\nAverage highly rated recall@k={k}: {avg_highly_rated_recall}\")\n","  print(f\"\\nAverage precision@k={k}: {avg_precision}\")\n","  print(f\"\\nAverage highly rated precision@k={k}: {avg_highly_rated_precision}\")\n","  print(f\"\\nAverage f1@k={k}: {avg_f1_score}\")\n","  print(f\"\\nAverage highly rated f1@k={k}: {avg_highly_rated_f1_score}\")\n","  print(f\"\\nNumber of users evaluated: {len(eval_user_ids)}\")\n"],"metadata":{"id":"oVyQfKYAiDpf","executionInfo":{"status":"ok","timestamp":1764728622206,"user_tz":300,"elapsed":13,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# load datasets\n","train_df = pd.read_csv('train_edges.csv')\n","test_df = pd.read_csv('test_edges.csv')"],"metadata":{"id":"Eb9f5_EKicGU","executionInfo":{"status":"ok","timestamp":1764728623587,"user_tz":300,"elapsed":1380,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_df = train_df.rename(columns={'User-ID':'user_id','Book-Rating': 'rating'})\n","test_df = test_df.rename(columns={'User-ID':'user_id','Book-Rating': 'rating'})"],"metadata":{"id":"GA0iDrzLiev8","executionInfo":{"status":"ok","timestamp":1764728623592,"user_tz":300,"elapsed":1,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["print(\"Before filtering test data:\")\n","valid_user_ids = list(set(train_df.user_id.unique()) & set(test_df.user_id.unique()))\n","print(f\"Evaluation users: {len(valid_user_ids)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NM5ugm00vvgW","executionInfo":{"status":"ok","timestamp":1764728623603,"user_tz":300,"elapsed":8,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}},"outputId":"14313549-d44f-4c1e-af4d-cd94d8846f0b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Before filtering test data:\n","Evaluation users: 9055\n"]}]},{"cell_type":"code","source":["min_user_test_entries = 5\n","filtered_test_df = filter_test_set(test_df, min_user_test_entries)"],"metadata":{"id":"xAQDroRVnj-w","executionInfo":{"status":"ok","timestamp":1764728623610,"user_tz":300,"elapsed":5,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e9d0cb3-ad03-484c-baa9-2aca4a58fd41"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({1: 4986, 2: 1458, 3: 681, 4: 416, 5: 269, 6: 199, 7: 130, 8: 126, 9: 96, 10: 72, 11: 64, 13: 59, 12: 54, 14: 46, 15: 35, 16: 34, 17: 32, 20: 25, 18: 23, 21: 20, 22: 19, 19: 17, 30: 15, 23: 14, 26: 13, 25: 13, 35: 10, 37: 8, 32: 8, 27: 8, 34: 7, 33: 7, 24: 7, 31: 6, 48: 5, 46: 5, 28: 5, 51: 4, 42: 4, 40: 4, 29: 4, 76: 3, 43: 3, 84: 2, 80: 2, 62: 2, 53: 2, 50: 2, 49: 2, 45: 2, 44: 2, 39: 2, 38: 2, 36: 2, 326: 1, 117: 1, 104: 1, 93: 1, 92: 1, 86: 1, 82: 1, 79: 1, 71: 1, 70: 1, 66: 1, 59: 1, 58: 1, 57: 1, 56: 1, 54: 1, 52: 1, 47: 1, 41: 1})\n"]}]},{"cell_type":"code","source":["print(\"After filtering test data:\")\n","valid_user_ids = list(set(train_df.user_id.unique()) & set(filtered_test_df.user_id.unique()))\n","print(f\"Evaluation users: {len(valid_user_ids)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rcgf1AVCv8KE","executionInfo":{"status":"ok","timestamp":1764728623623,"user_tz":300,"elapsed":11,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}},"outputId":"47cd985d-a163-47d0-dfd5-0308328e30dc"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["After filtering test data:\n","Evaluation users: 1514\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxIc3VOwgY2j","executionInfo":{"status":"ok","timestamp":1764728623703,"user_tz":300,"elapsed":79,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}},"outputId":"c457b085-398c-4d05-94ec-f78d4bca6b63"},"outputs":[{"output_type":"stream","name":"stdout","text":["data type: <class 'dict'>\n"]}],"source":["# read in recommendations from json file\n","# file_path = \"collaborative_filtering_recommendations_k_50_users_100.json\"\n","# file_path = \"item_based_collaborative_filtering_recommendations_k_50_items_50.json\"\n","file_path = \"neural_collaborative_filtering_recommendations_k_50.json\"\n","with open(file_path) as json_file:\n","  recommendations = json.load(json_file)\n","  print(\"data type:\", type(recommendations))"]},{"cell_type":"code","source":["# run evaluation: recall, precision, f1\n","k = 50\n","# evaluate on original test data\n","evaluate(recommendations, train_df, test_df, k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tBHjHCUQiF8V","executionInfo":{"status":"ok","timestamp":1764728644022,"user_tz":300,"elapsed":20312,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}},"outputId":"711a44a5-3779-454c-d18b-8b2ce1f45072"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9055/9055 [00:20<00:00, 446.54it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Average recall@k=50: 0.02705120687688505 for k = 50\n","\n","Average highly rated recall@k=50: 0.01697551546953054\n","\n","Average precision@k=50: 0.00462175593594699\n","\n","Average highly rated precision@k=50: 0.0017172832689122033\n","\n","Average f1@k=50: 0.0062398114942204186\n","\n","Average highly rated f1@k=50: 0.002874432244399456\n","\n","Number of users evaluated: 9055\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# evaluate on filtered test data\n","evaluate(recommendations, train_df, filtered_test_df, k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKz2uK2F-abj","executionInfo":{"status":"ok","timestamp":1764728648309,"user_tz":300,"elapsed":4285,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}},"outputId":"158ea1da-243b-4ee0-b295-03917a5bfa37"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1514/1514 [00:04<00:00, 354.70it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Average recall@k=50: 0.027652143287226393 for k = 50\n","\n","Average highly rated recall@k=50: 0.02689121042047492\n","\n","Average precision@k=50: 0.017569352708058126\n","\n","Average highly rated precision@k=50: 0.005746367239101717\n","\n","Average f1@k=50: 0.018924653884147154\n","\n","Average highly rated f1@k=50: 0.00874001866869081\n","\n","Number of users evaluated: 1514\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# evaluation functions for recommendation BIAS? tbd"],"metadata":{"id":"znE1Em_kfi-g","executionInfo":{"status":"ok","timestamp":1764728648316,"user_tz":300,"elapsed":3,"user":{"displayName":"Anna Yang","userId":"06008874035881470473"}}},"execution_count":18,"outputs":[]}]}